# Crime Prediction and Interpretability Using XGBoost and Random Forest

## Project Overview

Crime encompasses activities that violate laws and regulations and can range from minor infractions to serious offenses. Understanding crime patterns and trends is vital for developing effective law enforcement strategies. This project explores crime category predictions using XGBoost and Random Forest models on a dataset of San Francisco crime data spanning 12 years. Compared to other models like k-Nearest Neighbors (KNN), Stochastic Gradient Descent (SGD), and Naïve Bayes, XGBoost and Random Forest demonstrate superior predictive performance, as evidenced by competitive log-loss scores. Additionally, this project employs Local Interpretable Model-agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP) to enhance the interpretability of these models, providing deeper insights into the factors influencing crime predictions.

## Research Paper

For a detailed explanation of the methodologies and findings discussed in this project, please refer to the related research paper:

- **Title**: Interpretable Predictions for Crime Categories using Log Loss approach for imbalanced target feature.
- **Authors**: Manasa A, Snigdha Sen.
- **Abstract**: Crime indicates activities that infringe laws and regulations constituted by a governing authority. These wrongdoings can range from minor aberrations such as petty theft to more serious crimes like assault, robbery, or murder. Understanding crime patterns, causes, and trends is important for creating effective law enforcement strategies and enforcing policies that facilitate a risk-free and stable society. This paper explores the interpretability of crime category predictions generated by XGBoost and Random Forest models on San Francisco crime data spanning 12 years. Notably, in comparison to other models, such as k-Nearest Neighbors (KNN), Stochastic Gradient Descent (SGD), and Naïve Bayes, our XGBoost and Random Forest models featured superior predictive excellence, obtaining competitive log-loss scores of 2.277761 and 2.283956, respectively. To augment interpretability, we have employed Local Interpretable Model-agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP) to clarify the decision-making processes of these models. This interpretability analysis provides deeper insights into the contributing factors of the model’s predictive behavior towards crime rate prediction. Additionally, we have addressed the issue of imbalanced target features. Compared to existing research in the field, our work stands out by introducing advanced interpretability techniques, LIME and SHAP, enhancing transparency in crime prediction models. This innovative approach surpasses traditional methods, providing a more comprehensive understanding of crime dynamics and achieving superior predictive excellence.
- **DOI**: (https://doi.org/10.1109/InC460750.2024.10649054)
- **Link**: Read the Paper(https://ieeexplore.ieee.org/document/10649054)

## Methodology

### Data

- **Dataset**: San Francisco crime data covering 12 years.
- **Target Feature**: Crime categories.

### Models

- **XGBoost**: An optimized gradient boosting algorithm known for its predictive accuracy.
- **Random Forest**: An ensemble method utilizing multiple decision trees for improved classification performance.

### Comparison Models

- **k-Nearest Neighbors (KNN)**
- **Stochastic Gradient Descent (SGD)**
- **Naïve Bayes**

### Interpretability Techniques

- **LIME**: Local Interpretable Model-agnostic Explanations provide explanations for individual predictions by approximating the model locally with an interpretable model.
- **SHAP**: SHapley Additive exPlanations offer a unified measure of feature importance based on game theory, providing insights into the contributions of each feature to the model's predictions.

### Evaluation Metrics

- **Log-Loss**: A metric for classification models, where lower values indicate better performance. The project achieved log-loss scores of 2.277761 (XGBoost) and 2.283956 (Random Forest).

## Installation

To set up the project environment, follow these steps:

1. **Clone the Repository**

   ```bash
   git clone https://github.com/yourusername/crime-prediction.git
   cd crime-prediction
